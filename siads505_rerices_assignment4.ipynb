{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce7144d57d471f40",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "*version 190910.0*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a6c4f74309fc2379",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 4\n",
    "## Description\n",
    "In this assignment you must read in a file of metropolitan regions and associated sports teams from [assets/wikipedia_data.html](assets/wikipedia_data.html) and answer some questions about each metropolitan region. Each of these regions may have one or more teams from the \"Big 4\": NFL (football, in [assets/nfl.csv](assets/nfl.csv)), MLB (baseball, in [assets/mlb.csv](assets/mlb.csv)), NBA (basketball, in [assets/nba.csv](assets/nba.csv) or NHL (hockey, in [assets/nhl.csv](assets/nhl.csv)). Please keep in mind that all questions are from the perspective of the metropolitan region, and that this file is the \"source of authority\" for the location of a given sports team. Thus teams which are commonly known by a different area (e.g. \"Oakland Raiders\") need to be mapped into the metropolitan region given (e.g. San Francisco Bay Area). This will require some human data understanding outside of the data you've been given (e.g. you will have to hand-code some names, and might need to google to find out where teams are)!\n",
    "\n",
    "For each sport I would like you to answer the question: **what is the win/loss ratio's correlation with the population of the city it is in?** Remember that to calculate the correlation with [`pearsonr`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pearsonr.html), so you are going to send in two ordered lists of values, the populations from the wikipedia_data.html file and the win/loss ratio for a given sport in the same order. Average the win/loss ratios for those cities which have multiple teams of a single sport. Each sport is worth an equal amount in this assignment (20%\\*4=80%) of the grade for this assignment.\n",
    "\n",
    "In addition, I would like you to explore the hypothesis that **given that an area has two sports teams in different sports, those teams will perform the same within their respective sports**. How I would like to see this explored is with a series of paired t-tests (so use [`ttest_rel`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html)) between all pairs of sports. Are there any sports where we can reject the null hypothesis? Again, average values where a sport has multiple teams in one region. Remember, you will only be including, for each sport, cities which have teams engaged in that sport, drop others as appropriate. This question is worth 20% of the grade for this assignment.\n",
    "\n",
    "## Notes\n",
    "\n",
    "1. Partial marks may be awarded if the answer is incorrect, or removed even if the answer is correct! Within each function show your understanding of course concepts such as regex, `groupby()`, `apply()`, etc. as appropriate to the question. If you unnecessarily hand code data in your functions instead of using pandas cleaning mechanisms you may be docked grades.\n",
    "2. Do not including data about the MLS or CFL in any of the work you are doing, we're only interested in the Big 4 in this assignment.\n",
    "3. I highly suggest that you first tackle the correlation questions, as they are all similar and worth the majority of grades for this assignment. This is by design!\n",
    "4. It's fair game to talk with peers about high level strategy as well as the relationship between metropolitan areas and sports teams. However, do not post code solving aspects of the assignment (including such as dictionaries mapping areas to teams, or regexes which will clean up names).\n",
    "5. This assignment **is not autograded**. Go to the course shell and upload your .ipynb file there as assignment4.ipynb.\n",
    "6. You can earn up to 100% on this assignment by creating correlations for a single year (2016) for which there is population data. You can earn up to 105% on this assignment by going further, and creating correlations for multiple years (e.g. across the years of data we have on the sports), but it's expected that there would be a short discussion of the limitations of your approach as far as interpretation goes. Finally, if you find new population data that covers a broader set of years and integrate it into a solution across these years and sports and provide that interpretation you can earn up to 110% on the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import itertools\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of Data: Read and Group Sport Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Procedure__: first I load sport stats data and do some basic clean up and manipulation.\n",
    "\n",
    "Importantly for NHL data: \n",
    "- I correct half of data attributed to 2017 to be from 2016. \n",
    "- I calculate the W/L% ratio as W/(W+L) from the data at hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb_df = pd.read_csv(\"assets/mlb.csv\")\n",
    "\n",
    "nhl_df=pd.read_csv(\"assets/nhl.csv\")\n",
    "nhl_df.loc[nhl_df.duplicated(subset = ['team', 'year']), 'year'] = 2016 # correct second ocurrence of 2017 data to be of 2016\n",
    "nhl_df['W-L%'] = pd.to_numeric(nhl_df['W'], errors = 'coerce')/ (pd.to_numeric(nhl_df['W'], errors = 'coerce') + pd.to_numeric(nhl_df['L'], errors = 'coerce')) # create w/l% as defined by W/(W+L)\n",
    "\n",
    "nba_df=pd.read_csv(\"assets/nba.csv\")\n",
    "nba_df = nba_df.rename({'W/L%':'W-L%'}, axis = 1) # basic renaming\n",
    "\n",
    "nfl_df=pd.read_csv(\"assets/nfl.csv\")\n",
    "\n",
    "sport_stats = {'MLB': mlb_df, 'NHL': nhl_df, 'NBA':nba_df, 'NFL': nfl_df} # grouping for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation of Metropolitan Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Procedure Explanation__\n",
    "\n",
    "- First I loaded the raw html to a string, and performed two clean up operations:\n",
    "    1. replace hyperlinked text with the title tag in the href code, as it contains an already cleaned sports team name. An important feature during this cleanup is that I encircled contiguous team names in double quotes, so as to easily separate them afterwards when doing regex. \n",
    "    2. removed the notes that appeared next to the team names\n",
    "- This worked html was then fed to panda's html parser to extract the relevant cities table. \n",
    "- Then I expanded into several rows teams that were part of the same area, so that they could be merged properly later on. \n",
    "- I performed some additional cleanup for NaNs and legibility.\n",
    "- Finally I hard coded some team names that were not present in the table, but were available on the individual sport files. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-load HTML to clean team names in raw HTML\n",
    "cities = open(\"assets/wikipedia_data.html\", \"r\").read()\n",
    "\n",
    "pat_title = re.compile(r'(<a.*?title=\\\"(?P<title>.*?)\\\".*?<\\/a>)') \n",
    "cities = pat_title.sub('\\\"\\g<title>\\\"', cities) # replace bad content team names, with title tag names from href link\n",
    "pat_notes = re.compile(r'<sup(?:.|\\n)*?<\\/sup>') \n",
    "cities = pat_notes.sub('', cities) # remove notes from names\n",
    "\n",
    "# load DF from cleaned HTML\n",
    "cities = pd.read_html(cities)[1]\n",
    "cities = cities.iloc[:-1,[0,3,5,6,7,8]]\n",
    "\n",
    "# Rename columns for clarity\n",
    "cities = cities.rename({'\"Metropolitan area\"': 'Area', 'Population (2016 est.)': 'Population'}, axis = 1)\n",
    "\n",
    "# Clean NaNs \n",
    "cities = cities.replace('â€”',np.nan)\n",
    "\n",
    "# Expand Areas with Multiple Teams\n",
    "cities = (cities.set_index(['Area', 'Population'])\n",
    "   .stack()\n",
    "   .str.strip('\"') \n",
    "   .str.split('\"\"', expand=True) # splitting contiguous team names\n",
    "   .stack()\n",
    "   .unstack(-2)\n",
    "   .reset_index(-1, drop=True)\n",
    "   .reset_index()\n",
    "   .fillna('')\n",
    ")\n",
    "\n",
    "# Clean Team and Area Names\n",
    "cities['Area'] = cities['Area'].str.strip('\"')\n",
    "cities = (cities\n",
    "    .replace(to_replace = r'(?P<team>^[A-Z1-9][\\w\\. \\-]+)(.*)', value = '\\g<team>', regex = True) # further clean up of Team names \n",
    "    .replace(to_replace = r' metropolitan area', value = '', regex = True) # remove 'metropolitan area' from area names\n",
    "    .apply(lambda x: x.str.strip()) # further cleaning of whitespace \n",
    ")\n",
    "\n",
    "# Change/Coerce to Relevant dtype\n",
    "cities['Population'] = pd.to_numeric(cities.Population)\n",
    "\n",
    "# Manually Add San Diego Chargers, St. Louis Rams, Los Angeles Angels of Anneheim, Charlotte Bobcats and Phoenix Coyotes as they don't Exist in the DB due to Relocating/Renaming\n",
    "area = 'San Diego County'\n",
    "aux = pd.Series({'Area': area, 'Population': cities[cities.Area == area].Population.mean(), 'NFL':'San Diego Chargers', 'MLB':'', 'NBA':'', 'NHL':''}, name = 'Added')\n",
    "cities = cities.append(aux)\n",
    "area = 'Greater St. Louis'\n",
    "aux = pd.Series({'Area': area, 'Population': cities[cities.Area == area].Population.mean(), 'NFL':'St. Louis Rams', 'MLB':'', 'NBA':'', 'NHL':''}, name = 'Added')\n",
    "cities = cities.append(aux)\n",
    "area = 'Charlotte'\n",
    "aux = pd.Series({'Area': area, 'Population': cities[cities.Area == area].Population.mean(), 'NFL':'', 'MLB':'', 'NBA':'Charlotte Bobcats', 'NHL':''}, name = 'Added')\n",
    "cities = cities.append(aux)\n",
    "area = 'Los Angeles'\n",
    "aux = pd.Series({'Area': area, 'Population': cities[cities.Area == area].Population.mean(), 'NFL':'', 'MLB':'Los Angeles Angels of Anaheim', 'NBA':'', 'NHL':''}, name = 'Added')\n",
    "cities = cities.append(aux)\n",
    "area = 'Phoenix'\n",
    "aux = pd.Series({'Area': area, 'Population': cities[cities.Area == area].Population.mean(), 'NFL':'', 'MLB':'', 'NBA':'', 'NHL':'Phoenix Coyotes'}, name = 'Added')\n",
    "cities = cities.append(aux)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process and Merge Sports Data with Population Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two functions are used to clean up the sports data and to merge it with the population data. \n",
    "\n",
    "1. clean_stats Function:\n",
    "    - It cleans up team names by doing a regex and replacing what it founds with the contents of a group which I called team. \n",
    "    - It also coerces W-L% to numerical data, and removes any rows that produce a NaN during coercion, this is to eliminate rows that do not have relevant team data, like headers. \n",
    "2. merge_panels Function:\n",
    "    - first it cleans up the sports panel with the previous function\n",
    "    - then subselects just relevant columns and rows for a given year\n",
    "    - merges resulting data with population data while at the same time aggregating results with an average as indicated at the area level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_stats(sport_stats):\n",
    "    sport_stats['team'] = sport_stats['team'].replace(to_replace = r'(?P<team>^[A-Z1-9][\\w\\. \\-]+)(.*)', value = '\\g<team>', regex = True) # clean team names\n",
    "    sport_stats['W-L%'] = pd.to_numeric(sport_stats['W-L%'], errors = 'coerce') \n",
    "    sport_stats = sport_stats.dropna(subset = ['W-L%']) # remove non-relevant non-numeric rows\n",
    "    return sport_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_panels(sport_stats, cities, sport, year):\n",
    "    # clean panel\n",
    "    sport_stats = clean_stats(sport_stats[sport])\n",
    "    \n",
    "    # select relevant data\n",
    "    sport_stats = sport_stats[sport_stats.year == year][['team', 'W-L%']]\n",
    "    cities = cities[['Area', 'Population', sport]].rename({sport:'team'}, axis = 1)\n",
    "    \n",
    "    # merge and group relevant data\n",
    "    sport_stats = sport_stats.merge(cities, on = 'team', how = 'left') # merge with population\n",
    "    sport_stats = sport_stats.groupby('Area').agg({'Population': np.mean, 'W-L%': np.mean})\n",
    "    \n",
    "    return sport_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation Functions\n",
    "\n",
    "Below are the functions used to calculate main results. The most important ones are two:\n",
    "\n",
    "1. sport_correlation Function:\n",
    "    - given a sport, panel of sport stats, panel of cities with population/teams and a year it calculates the correlation of W-L% with Population\n",
    "    - it mainly uses the merge_panels function described earlier\n",
    "    - it includes an error grabbing routine in case there are no relevant data to be used (wrong year for example)\n",
    "    \n",
    "    \n",
    "2. sports_team_performance Function:\n",
    "    - given a panel of sport stats, panel of cities with population/teams and a year it calculates the paired t-test for all combinations of sports in the sports stats panel \n",
    "    - it uses the merge_panel clean up function described earlier, and importantly it merges both frames with an inner join to only consider areas that have sport teams in both sports \n",
    "\n",
    "\n",
    "3. specific sports Functions: \n",
    "    - those are just calls to the more general function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sport_correlation(sport, sport_stats, cities, year = 2017):\n",
    "    data = merge_panels(sport_stats, cities, sport, year)\n",
    "    population_by_region = data['Population']\n",
    "    win_loss_by_region = data['W-L%']\n",
    "    try: \n",
    "        value = stats.pearsonr(population_by_region, win_loss_by_region)\n",
    "    except:\n",
    "        value = (np.nan, np.nan)\n",
    "        \n",
    "    return value\n",
    "\n",
    "def nhl_correlation(year = 2016): # worth 20% of the assignment grade\n",
    "    return sport_correlation('NHL', sport_stats, cities, year)\n",
    "\n",
    "def nba_correlation(year = 2016): # worth 20% of the assignment grade\n",
    "    return sport_correlation('NBA', sport_stats, cities, year)\n",
    "\n",
    "def mlb_correlation(year = 2016): # worth 20% of the assignment grade\n",
    "    return sport_correlation('MLB', sport_stats, cities, year)\n",
    "\n",
    "def nfl_correlation(year = 2016): # worth 20% of the assignment grade\n",
    "    return sport_correlation('NFL', sport_stats, cities, year)\n",
    "\n",
    "def sports_team_performance(sport_stats, cities, year = 2016) : # worth 20% of the assignment grade\n",
    "    sports = sport_stats.keys()\n",
    "    p_values = pd.DataFrame({k:np.nan for (k) in sports},index=sports)\n",
    "    \n",
    "    for pair in itertools.permutations(sports, 2):\n",
    "        sport1 = merge_panels(sport_stats, cities, pair[0], year)[['W-L%']]\n",
    "        sport2 = merge_panels(sport_stats, cities, pair[1], year)[['W-L%']]\n",
    "        both_sports = sport1.merge(sport2, on = 'Area', how = 'inner')\n",
    "        p_values.loc[pair[0], pair[1]] = stats.ttest_rel(both_sports['W-L%_x'], both_sports['W-L%_y']).pvalue\n",
    "    return p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts 1 - 4: Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation for 2016 of population and W-L% for MLB is 0.2461879894080591\n",
      "The correlation for 2016 of population and W-L% for NHL is 0.31580627948704787\n",
      "The correlation for 2016 of population and W-L% for NBA is -0.18769238444022995\n",
      "The correlation for 2016 of population and W-L% for NFL is -0.06106574171738971\n"
     ]
    }
   ],
   "source": [
    "for sport in sport_stats.keys():\n",
    "    print('The correlation for 2016 of population and W-L% for {} is {}'.format(sport, sport_correlation(sport, sport_stats, cities, year = 2016)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Paired Tests\n",
    "\n",
    "__Interpretation__\n",
    "\n",
    "As its noticeable from the results below the null hypothesis of equal performance of teams for differents sports given an area can be rejected at a 5% confidence level for the pair __MLB/NHL__ and __NHL/NFL__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLB</th>\n",
       "      <th>NHL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NFL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>MLB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.799103</td>\n",
       "      <td>0.572215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NHL</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.039501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NBA</td>\n",
       "      <td>0.799103</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NFL</td>\n",
       "      <td>0.572215</td>\n",
       "      <td>0.039501</td>\n",
       "      <td>0.950015</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MLB       NHL       NBA       NFL\n",
       "MLB       NaN  0.000111  0.799103  0.572215\n",
       "NHL  0.000111       NaN  0.074380  0.039501\n",
       "NBA  0.799103  0.074380       NaN  0.950015\n",
       "NFL  0.572215  0.039501  0.950015       NaN"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_team_performance(sport_stats, cities, year = 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLB</th>\n",
       "      <th>NHL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NFL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>MLB</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NHL</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NBA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NFL</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       MLB    NHL    NBA    NFL\n",
       "MLB  False   True  False  False\n",
       "NHL   True  False  False   True\n",
       "NBA  False  False  False  False\n",
       "NFL  False   True  False  False"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports_team_performance(sport_stats, cities, year = 2016) < 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Correlation over the Years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Limitation of the exercise__: the correlation over the years quite simply uses static population data for each area, which of course is going to affect correlation coefficients for years different to 2016, given this is the one for which we know the population figures. Any changes observed over time in the coefficients might be due to changing demographics not accounted for, and not due to the relationship per se. \n",
    "\n",
    "__Procedure__: the function below quite simply calls the sport_correlation function as defined for the main portion of the assignment, but changes the years for which it is calculated. Importantly, this does not change the cities frame that contains population data, but just filters sport stats based on the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_correlation(sport_stats, cities):\n",
    "    sports = sport_stats.keys()\n",
    "    correlations = pd.DataFrame()\n",
    "    \n",
    "    for year in range(2014,2019):\n",
    "        for sport in sports:\n",
    "            correlations.loc[year, sport] = sport_correlation(sport, sport_stats, cities, year)[0]\n",
    "        \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Correlation Coefficient for Sports with Static Area Population over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLB</th>\n",
       "      <th>NHL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NFL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>0.031091</td>\n",
       "      <td>0.229168</td>\n",
       "      <td>0.109021</td>\n",
       "      <td>-0.190503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0.206464</td>\n",
       "      <td>0.160268</td>\n",
       "      <td>-0.065090</td>\n",
       "      <td>-0.077871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>0.246188</td>\n",
       "      <td>0.315806</td>\n",
       "      <td>-0.187692</td>\n",
       "      <td>-0.061066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>0.063575</td>\n",
       "      <td>0.225120</td>\n",
       "      <td>-0.200451</td>\n",
       "      <td>-0.189007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>0.150037</td>\n",
       "      <td>0.012486</td>\n",
       "      <td>-0.176364</td>\n",
       "      <td>0.004282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MLB       NHL       NBA       NFL\n",
       "2014  0.031091  0.229168  0.109021 -0.190503\n",
       "2015  0.206464  0.160268 -0.065090 -0.077871\n",
       "2016  0.246188  0.315806 -0.187692 -0.061066\n",
       "2017  0.063575  0.225120 -0.200451 -0.189007\n",
       "2018  0.150037  0.012486 -0.176364  0.004282"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_correlation(sport_stats, cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Additional Population Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part of the assignment I downloaded metropolitan population data from the OCDE website (available here, https://stats.oecd.org/Index.aspx?DataSetCode=CITIES#).\n",
    "\n",
    "__Assumptions:__\n",
    "   - I ignored in the analysis those areas for which the OCDE has no population data, but for which the original Wikipedia article has data. \n",
    "   - The OCDE data is updated until 2016, so I extrapolated the population linearly for each area on a yearly basis from 2017 to 2018\n",
    "   \n",
    "__Explanation of the procedure:__\n",
    "- First I load the new population data and extrapolate data for unavailable years. \n",
    "- Then I constructed a function, city_population(cities, year), which given the original 'cities' frame and a year, updates population figures for the 'cities' table. \n",
    "    - The linkage of areas is made using an externally provided area-names dictionary that I constructed by hand. \n",
    "- The next step was to construct a slightly modified version of the function that gives the correlation for different years for each sport that updates the 'cities' frame before handing it over to the function that computes the correlation.\n",
    "    - The previous functions were constructed in such a way that the 'cities' frame was always to be given, so it was easy to just provide a new 'cities' frame.\n",
    "\n",
    "__Limitations:__\n",
    "- One important limitation is that the metropolitan areas might not necesarrily be the same as those on the original table, I just randomly checked a couple of cities to test whether the populations were more or less of the same order of magnitude\n",
    "- Another limitation is that some areas that have important teams were ignored due to missing data (e.g. Cleveland)\n",
    "- One last limitation is that the extrapolation procedure might not reflect properly correct changes in demographics over time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = pd.read_csv('cities.csv')\n",
    "population_data = population_data[population_data.Variables == 'Population, All ages. Administrative data']#[['Metropolitan areas', 'Year', 'Value ']]\n",
    "population_data = population_data.drop(['METRO_ID', 'Variables'], axis = 1)\n",
    "population_data.columns = ['Area', 'Year', 'Population']\n",
    "\n",
    "extrapolated = pd.pivot_table(population_data, index = 'Area', values = 'Population', columns = 'Year')\n",
    "extrapolated[2017] = extrapolated[2016]*(1+(extrapolated[2016]/extrapolated[2015] - 1))\n",
    "extrapolated[2018] = extrapolated[2017]*(1+(extrapolated[2017]/extrapolated[2016] - 1))\n",
    "population_data = extrapolated.unstack().reset_index()    \n",
    "population_data.columns = ['Year', 'Area', 'Population']\n",
    "\n",
    "names_dictionary = pd.read_csv('areas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def city_population(cities, year):\n",
    "    cities = cities.merge(names_dictionary, on = 'Area', how = 'left').merge(population_data[population_data.Year == year], left_on = 'SecondArea', right_on = 'Area', how = 'left')\n",
    "    cities = cities.drop(['Population_x', 'Area_y', 'Year', 'SecondArea'], axis = 1)\n",
    "    cities = cities.rename({'Area_x': 'Area', 'Population_y': 'Population'}, axis = 1)\n",
    "    cities = cities.dropna(subset = ['Population'])\n",
    "    return cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yearly_correlation_changing_pop(sport_stats, cities):\n",
    "    sports = sport_stats.keys()\n",
    "    correlations = pd.DataFrame()\n",
    "    \n",
    "    for year in range(2014,2019):\n",
    "        cities = city_population(cities, year)\n",
    "        for sport in sports:\n",
    "            correlations.loc[year, sport] = sport_correlation(sport, sport_stats, cities, year)[0]\n",
    "        \n",
    "    return correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Correlation Coefficient for Sports with Changing Area Population over Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result below corresponds to the correlation coefficient of W/L% with population with changing population over time. This overcomes the limitation on the previous section for which there might be a factor unaccounted for when calculating correlations. \n",
    "\n",
    "__The results do not change significantly.__ Meaning that apart from the result for NHL2018 none of the correlations changes sign and were of approximate magnitude. Its important to note that population measures do not coincide even for the year 2016, as such, I did not expect to get the exact same values. \n",
    "\n",
    "__However I did expect to see even fewer magnitudal changes to the correlations__, as I thought that the variance in W/L% would completely overwhelm changing population metrics as those tend to be quite stable even for different datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MLB</th>\n",
       "      <th>NHL</th>\n",
       "      <th>NBA</th>\n",
       "      <th>NFL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2014</td>\n",
       "      <td>0.256992</td>\n",
       "      <td>0.131513</td>\n",
       "      <td>0.053224</td>\n",
       "      <td>-0.113911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2015</td>\n",
       "      <td>0.287228</td>\n",
       "      <td>0.032083</td>\n",
       "      <td>-0.075039</td>\n",
       "      <td>-0.081683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2016</td>\n",
       "      <td>0.393244</td>\n",
       "      <td>0.314759</td>\n",
       "      <td>-0.179691</td>\n",
       "      <td>-0.159941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2017</td>\n",
       "      <td>0.207847</td>\n",
       "      <td>0.204622</td>\n",
       "      <td>-0.183235</td>\n",
       "      <td>-0.261311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018</td>\n",
       "      <td>0.033637</td>\n",
       "      <td>-0.074248</td>\n",
       "      <td>-0.169876</td>\n",
       "      <td>0.059023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           MLB       NHL       NBA       NFL\n",
       "2014  0.256992  0.131513  0.053224 -0.113911\n",
       "2015  0.287228  0.032083 -0.075039 -0.081683\n",
       "2016  0.393244  0.314759 -0.179691 -0.159941\n",
       "2017  0.207847  0.204622 -0.183235 -0.261311\n",
       "2018  0.033637 -0.074248 -0.169876  0.059023"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yearly_correlation_changing_pop(sport_stats, cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ______________________________\n",
      "< hopefully I get full grades! >\n",
      " ------------------------------\n",
      "        \\   ^__^\n",
      "         \\  (oo)\\_______\n",
      "            (__)\\       )\\/\\\n",
      "                ||----w |\n",
      "                ||     ||\n"
     ]
    }
   ],
   "source": [
    "!cowsay 'hopefully I get full grades!'"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
